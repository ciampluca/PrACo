{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating modified dataset for new training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo.pierucci/anaconda3/envs/clipcount/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data_mod/FSC/FSC_147\"\n",
    "split_images_file = \"Train_Test_Val_FSC_147.json\"\n",
    "dot_annotations_file = \"annotation_FSC147_384.json\"\n",
    "split_classes_file = \"Split_Classes_FSC147.json\"\n",
    "descriptions_file = \"./FSC-147-D.json\"\n",
    "\n",
    "img_class_txt = \"ImageClasses_FSC147.txt\"\n",
    "\n",
    "with open(os.path.join(data_dir, split_images_file), 'r') as f:\n",
    "    split_images = json.load(f)    \n",
    "    \n",
    "with open(os.path.join(data_dir, dot_annotations_file), 'r') as f:\n",
    "    dot_annotations = json.load(f)\n",
    "    \n",
    "with open( descriptions_file, 'r') as f:\n",
    "    descriptions = json.load(f)\n",
    "    \n",
    "with open(os.path.join(data_dir, split_classes_file), 'r') as f:\n",
    "    split_classes = json.load(f)\n",
    "    \n",
    "img_classes = {}\n",
    "\n",
    "with open(os.path.join(data_dir, img_class_txt), 'r') as file:\n",
    "    for line in file:\n",
    "        line = line.strip().split('\\t')\n",
    "        if len(line) == 2:\n",
    "            img_name, label = line\n",
    "            img_classes[img_name] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = split_images['train']\n",
    "val_list = split_images['val']\n",
    "train_val_images = train_list + val_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_directory = './data_mod/FSC/images_384_VarV2'\n",
    "density_directory = './data_mod/FSC/gt_density_map_adaptive_384_VarV2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4945/4945 [01:23<00:00, 58.93it/s] \n"
     ]
    }
   ],
   "source": [
    "random.seed(123)\n",
    "new_im_id = 7715\n",
    "\n",
    "for img_filename in tqdm.tqdm(train_val_images):\n",
    "    \n",
    "    img = Image.open(os.path.join(img_directory, img_filename))\n",
    "    img.load()\n",
    "    \n",
    "    new_filename = f\"{new_im_id}.jpg\"\n",
    "    img.save(os.path.join(img_directory, new_filename))\n",
    "    \n",
    "    loaded_density_map = np.load(os.path.join(density_directory, img_filename.split('.')[0] + '.npy' ))\n",
    "    density_shape = loaded_density_map.shape\n",
    "    density_map = np.zeros(density_shape, dtype=np.float32)\n",
    "    \n",
    "    density_filename = f\"{new_im_id}.npy\"\n",
    "    np.save(os.path.join(density_directory, density_filename), density_map)\n",
    "    \n",
    "    if img_filename in train_list:\n",
    "        split_images['train'].extend([new_filename])\n",
    "    elif img_filename in val_list:\n",
    "        split_images['val'].extend([new_filename])\n",
    "    \n",
    "    cur_img_class = img_classes[img_filename]\n",
    "    new_img_class = cur_img_class\n",
    "    \n",
    "    if img_filename in train_list:\n",
    "        while new_img_class == cur_img_class:\n",
    "            new_img_class = split_classes['train'][random.randint(0, len(split_classes['train']) - 1)]\n",
    "    elif img_filename in val_list:\n",
    "         while new_img_class == cur_img_class:\n",
    "            new_img_class = split_classes['val'][random.randint(0, len(split_classes['val']) - 1)]\n",
    "            \n",
    "    img_classes[new_filename] = new_img_class\n",
    "    \n",
    "    new_image_descr = {\n",
    "        \"data_split\": \"train\" if img_filename in train_list else \"val\",\n",
    "        \"text_description\": f\"the {new_img_class}\"\n",
    "    }\n",
    "\n",
    "    descriptions[new_filename] = new_image_descr\n",
    "    \n",
    "    H = dot_annotations[img_filename][\"H\"]\n",
    "    W = dot_annotations[img_filename][\"W\"]\n",
    "    #box_examples_coordinates = dot_annotations[img_filename][\"box_examples_coordinates\"]\n",
    "    #box_examples_path = dot_annotations[img_filename][\"box_examples_path\"]\n",
    "    #density_path = dot_annotations[img_filename][\"density_path\"]\n",
    "    #density_path_fixed = dot_annotations[img_filename][\"density_path_fixed\"]\n",
    "    #img_path = dot_annotations[img_filename][\"img_path\"]\n",
    "    #points = dot_annotations[img_filename][\"points\"]\n",
    "    r = dot_annotations[img_filename][\"r\"]\n",
    "    ratio_h = dot_annotations[img_filename][\"ratio_h\"]\n",
    "    ratio_w = dot_annotations[img_filename][\"ratio_w\"]\n",
    "    \n",
    "    new_image_annotation = {\n",
    "        \"H\": H,\n",
    "        \"W\": W,\n",
    "        \"box_examples_coordinates\": [],\n",
    "        \"box_examples_path\": '',\n",
    "        \"density_path\": '',\n",
    "        \"density_path_fixed\": '',\n",
    "        \"img_path\": '',\n",
    "        \"points\": [],\n",
    "        \"r\": r,\n",
    "        \"ratio_h\": ratio_h,\n",
    "        \"ratio_w\": ratio_w\n",
    "    }\n",
    "    \n",
    "    dot_annotations[new_filename] = new_image_annotation\n",
    "    \n",
    "    new_im_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_images_mod_file = \"Train_Test_Val_FSC_147_mod.json\"\n",
    "img_class_mod_txt = \"ImageClasses_FSC147_mod.txt\"\n",
    "descriptions_mod_file = \"./FSC-147-D_mod.json\"\n",
    "dot_annotations_mod_file = \"annotation_FSC147_384_mod.json\"\n",
    "\n",
    "with open(os.path.join(data_dir, split_images_mod_file), 'w') as file:\n",
    "    json.dump(split_images, file, indent=4)\n",
    "    \n",
    "with open(os.path.join(data_dir, img_class_mod_txt), 'w') as file:\n",
    "    for key, value in img_classes.items():\n",
    "        file.write(f\"{key}\\t{value}\\n\")\n",
    "        \n",
    "with open(descriptions_mod_file, 'w') as file:\n",
    "    json.dump(descriptions, file, indent=4)\n",
    "    \n",
    "with open(os.path.join(data_dir, dot_annotations_mod_file), 'w') as file:\n",
    "    json.dump(dot_annotations, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check on created density maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_density_map = np.load(os.path.join(density_directory, '7715.npy'.split('.')[0] + '.npy' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.Tensor(loaded_density_map)\n",
    "torch.sum(tensor).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = dot_annotations['7715.jpg'][\"points\"]\n",
    "len(points)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clipcount",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
